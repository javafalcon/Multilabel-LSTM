{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trX.shape: (4578, 32, 32)\n",
      "trY.shape: (4578, 24)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "data  = np.load('mydata.npz')\n",
    "trX, trY = data[ 'datax' ], data[ 'datay' ]\n",
    "print(\"trX.shape:\",trX.shape)\n",
    "print(\"trY.shape:\",trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trX.shape: (4578, 32, 32)\n",
      "trY.shape: (4578, 24)\n"
     ]
    }
   ],
   "source": [
    "# shuffling the arrays\n",
    "shuffling = list(zip(trX, trY))\n",
    "random.shuffle(shuffling)\n",
    "trX, trY = zip(*shuffling)\n",
    "trX = np.asarray(trX)\n",
    "trY = np.asarray(trY)\n",
    "print(\"trX.shape:\",trX.shape)\n",
    "print(\"trY.shape:\",trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teX.shape: (978, 32, 32)\n",
      "teY.shape: (978, 24)\n",
      "trX.shape: (3600, 32, 32)\n",
      "trY.shape: (3600, 24)\n"
     ]
    }
   ],
   "source": [
    "teX, teY = trX [ 3600:  ], trY [ 3600:  ]  # testset\n",
    "print(\"teX.shape:\",teX.shape)\n",
    "print(\"teY.shape:\",teY.shape)\n",
    "trX, trY = trX [ :3600  ], trY [ :3600 ]  # trainset\n",
    "print(\"trX.shape:\",trX.shape)\n",
    "print(\"trY.shape:\",trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(978, 1024)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trX = trX.reshape( -1, 32, 32, 1)\n",
    "teX = teX.reshape( -1, 1024)\n",
    "teY = teY.reshape( -1, 24)\n",
    "teX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Round:0\", shape=(8, ?, 3), dtype=float32) [<tf.Tensor 'split_7:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'split_7:1' shape=(?, 3) dtype=float32>, <tf.Tensor 'split_7:2' shape=(?, 3) dtype=float32>, <tf.Tensor 'split_7:3' shape=(?, 3) dtype=float32>, <tf.Tensor 'split_7:4' shape=(?, 3) dtype=float32>, <tf.Tensor 'split_7:5' shape=(?, 3) dtype=float32>, <tf.Tensor 'split_7:6' shape=(?, 3) dtype=float32>, <tf.Tensor 'split_7:7' shape=(?, 3) dtype=float32>]\n",
      "   0, cost_tr:  5.8 , cost_te:  5.9 , trainAccu: 0.74 , testAccu: 0.76 \n",
      "  10, cost_tr:    6 , cost_te:  5.9 , trainAccu: 0.79 , testAccu: 0.76 \n",
      "  20, cost_tr:  5.8 , cost_te:  5.8 , trainAccu: 0.76 , testAccu: 0.75 \n",
      "  30, cost_tr:  5.9 , cost_te:  5.9 , trainAccu: 0.77 , testAccu: 0.75 \n",
      "  40, cost_tr:  5.8 , cost_te:    6 , trainAccu: 0.82 , testAccu: 0.77 \n",
      "  50, cost_tr:  6.1 , cost_te:  5.9 , trainAccu: 0.78 , testAccu: 0.75 \n",
      "  60, cost_tr:    6 , cost_te:  5.9 , trainAccu: 0.79 , testAccu: 0.75 \n",
      "  70, cost_tr:  5.9 , cost_te:  5.9 , trainAccu:  0.8 , testAccu: 0.76 \n",
      "  80, cost_tr:  5.9 , cost_te:  5.9 , trainAccu: 0.75 , testAccu: 0.76 \n",
      "  90, cost_tr:  5.8 , cost_te:  5.9 , trainAccu: 0.76 , testAccu: 0.74 \n"
     ]
    }
   ],
   "source": [
    "class multinetwork(object):\n",
    "    def __init__(self,x,y,lr):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.lr = lr\n",
    "        self.opti = multinetwork.optimizer(self)\n",
    "        self.cos = multinetwork.cost(self)\n",
    "        self.acc1,self.acc2 = multinetwork.accuracy(self)\n",
    "        self.scores,self.labels = multinetwork.test(self)\n",
    "\n",
    "\n",
    "    def net(self):\n",
    "\n",
    "        x = tf.reshape(self.x,shape=[-1,32,32,1])\n",
    "\n",
    "        # w0 = tf.Variable(tf.random_normal([3, 3, 1, 32]))\n",
    "        # b0 = tf.Variable(tf.random_normal([32]))\n",
    "        # x_0 = tf.nn.relu(tf.nn.conv2d(x, w0, strides=[1, 1, 1, 1], padding=\"SAME\") + b0)\n",
    "        # p_0 = tf.nn.max_pool(x_0, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "        w1 = tf.Variable(tf.random_normal([3,3,1,8]))\n",
    "        b1 = tf.Variable(tf.random_normal([8]))\n",
    "        x_1 = tf.nn.tanh(tf.nn.conv2d(x,w1,strides=[1,1,1,1],padding=\"SAME\") + b1)\n",
    "        p_1 = tf.nn.max_pool(x_1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "        w2 = tf.Variable(tf.random_normal([3,3,8,32]))\n",
    "        b2 = tf.Variable(tf.random_normal([32]))\n",
    "        x_2 = tf.nn.tanh(tf.nn.conv2d(p_1,w2,strides=[1,1,1,1],padding=\"SAME\") + b2)\n",
    "        p_2 = tf.nn.max_pool(x_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "\n",
    "        w_f1 = tf.Variable(tf.random_normal([8*8*32,128]))\n",
    "        b_f1 = tf.Variable(tf.random_normal([128]))\n",
    "        p_2f = tf.reshape(p_2,[-1,8*8*32])\n",
    "        f_1 = tf.nn.tanh(tf.matmul(p_2f,w_f1) + b_f1)\n",
    "        f_1d = tf.nn.dropout(f_1,0.5)\n",
    "\n",
    "        w_f2 = tf.Variable(tf.random_normal([128,24]))\n",
    "        b_f2 = tf.Variable(tf.random_normal([24]))\n",
    "        prediction = tf.matmul(f_1d,w_f2) + b_f2\n",
    "\n",
    "        tf.summary.histogram('pred', prediction)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def cost(self):\n",
    "        self.score = self.net()\n",
    "        score_split = tf.split(self.score,8,1)\n",
    "        label_split = tf.split(self.y,8,1)\n",
    "        total = 0.0\n",
    "        for i in range ( len(score_split)  ):\n",
    "            total += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits= score_split[i] ,labels= label_split[i] ))\n",
    "        return total/8\n",
    "\n",
    "    def optimizer(self):\n",
    "        return tf.train.AdamOptimizer(learning_rate= self.lr).minimize(self.cost())\n",
    "\n",
    "    def test(self):\n",
    "        self.score = self.net()\n",
    "        score_split = tf.split(self.score, 8, 1)\n",
    "        label_split = tf.split(self.y, 8, 1)\n",
    "        score_split = tf.round(tf.divide(tf.abs(score_split),1e+05,name=None),name=None)\n",
    "        print(score_split,label_split)\n",
    "        return  score_split,label_split\n",
    "\n",
    "    def accuracy(self):\n",
    "        self.score = self.net()\n",
    "        score_split = tf.split(self.score, 8, 1)\n",
    "        label_split = tf.split(self.y, 8, 1)\n",
    "\n",
    "        correct_pred1 = tf.equal(tf.argmax(score_split[0], 1), tf.argmax(label_split[0], 1))\n",
    "        correct_pred2 = tf.equal(tf.argmax(score_split[1], 1), tf.argmax(label_split[1], 1))\n",
    "\n",
    "        return correct_pred1, correct_pred2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = tf.placeholder(tf.float32, [None, 32*32])\n",
    "    y = tf.placeholder(tf.float32, [None, 24])\n",
    "    lr = 0.1\n",
    "    network = multinetwork(x,y,lr)\n",
    "    batch_size = 200\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        index = 0\n",
    "\n",
    "        for batch_i in range(100):\n",
    "            trData_i, trLabel_i = [], []\n",
    "\n",
    "            trData_i .append( trX[ index : index + batch_size ] )\n",
    "            trLabel_i.append( trY[ index : index + batch_size ] )\n",
    "            index += batch_size\n",
    "            if index > ( len(trX) - batch_size+1 ):\n",
    "                index = 0\n",
    "            trData_i = np.reshape(trData_i, (-1, 32 * 32))\n",
    "            trLabel_i = np.reshape(trLabel_i, (-1, 24))\n",
    "\n",
    "\n",
    "            sess.run(network.opti, feed_dict={x: trData_i, y: trLabel_i})\n",
    "            if batch_i % 10 == 0:\n",
    "                cost_tr = sess.run(network.cos, feed_dict={x: trData_i, y: trLabel_i})\n",
    "                cost_te = sess.run(network.cos, feed_dict={x: teX[:3000], y: teY[:3000]})\n",
    "                tf.summary.scalar('train_loss',cost_tr)\n",
    "                tf.summary.scalar('test_loss',cost_te)\n",
    "                # test accuracy\n",
    "                accu1, accu2 = sess.run([network.acc1,network.acc2],\n",
    "                                        feed_dict={x: teX[:3000], y: teY[:3000]})\n",
    "                # print accu1,accu2\n",
    "                sc,lb = sess.run([network.scores,network.labels],\n",
    "                                        feed_dict={x: teX[:3000], y: teY[:3000]})\n",
    "\n",
    "\n",
    "                numOfposit = 0.0\n",
    "                for tt in range(accu1.shape[0]):\n",
    "                    if accu1[tt] == accu2[tt] or accu1[tt] == True:\n",
    "                        numOfposit += 1\n",
    "                test_accu = numOfposit / accu1.shape[0]\n",
    "\n",
    "                accu1, accu2 = sess.run([network.acc1,network.acc2],\n",
    "                                        feed_dict={x: trData_i, y: trLabel_i})\n",
    "                numOfposit = 0.0\n",
    "                for tt in range(accu1.shape[0]):\n",
    "                    if accu1[tt] == accu2[tt] or accu1[tt] == True:\n",
    "                        numOfposit += 1\n",
    "                train_accu = numOfposit / accu1.shape[0]\n",
    "                print(\"%4d, cost_tr: %4.2g , cost_te: %4.2g , trainAccu: %4.2g , testAccu: %4.2g \" % (\n",
    "                batch_i, cost_tr, cost_te, train_accu, test_accu))\n",
    "\n",
    "    writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "    merge_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
